{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOL1archive/ClauseSummary/blob/main/model-train/main-model-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWgJmALSfMI2"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "'Process in Colab' if IN_COLAB else 'Process in Local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PR27N0HfMI4"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install transformers\n",
        "    !pip install datasets\n",
        "    !pip install evaluate\n",
        "    !pip install rouge_score\n",
        "    !pip install torchmetrics\n",
        "    !pip install rouge\n",
        "    !pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt4-ma3vfMI4"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My0Nr3cZf-Kz"
      },
      "outputs": [],
      "source": [
        "# 깃허브에서는 빼야됨\n",
        "%cd drive/MyDrive/projects/ClauseSummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bubQc3pCfMI5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import datetime\n",
        "import os\n",
        "import gc\n",
        "from pprint import pprint\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorboard\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, CyclicLR\n",
        "import torchmetrics\n",
        "\n",
        "from datasets import load_dataset, load_from_disk, concatenate_datasets, DatasetDict, Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import BartConfig, T5Config, LongformerConfig\n",
        "from transformers import AutoTokenizer, LongformerTokenizer, AutoModelForSeq2SeqLM, LongT5ForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TSsz3ESfMI5"
      },
      "outputs": [],
      "source": [
        "class TokenizeMapWrapper:\n",
        "    def __init__(self, tokenizer, feature, option=None):\n",
        "        if option is None:\n",
        "            option = {\n",
        "                'max_new_tokens': 4096,\n",
        "                'truncation': True,\n",
        "                'padding': 'max_length',\n",
        "            }\n",
        "\n",
        "        self.option = option\n",
        "        self.feature = feature\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, row):\n",
        "        return self.tokenizer(row[self.feature], **self.option)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(tokenizer={self.tokenizer})'\n",
        "\n",
        "class Seq2SeqTokenizeMapWrapper(TokenizeMapWrapper):\n",
        "    def __init__(self, tokenizer, feature, target, option=None):\n",
        "        super().__init__(tokenizer, feature, option)\n",
        "        self.target = target\n",
        "\n",
        "    def seq2seq_tokenize(self, row):\n",
        "        form_embeddings = self.tokenizer(row[self.feature], **self.option)\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "            correct_form_embeddings = self.tokenizer(row[self.target], **self.option)\n",
        "\n",
        "        return {\n",
        "            'input_ids': form_embeddings['input_ids'],\n",
        "            'attention_mask': form_embeddings['attention_mask'],\n",
        "            'labels': correct_form_embeddings['input_ids'],\n",
        "        }\n",
        "\n",
        "    def __call__(self, row):\n",
        "        return self.seq2seq_tokenize(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8dFz3zAfMI5"
      },
      "source": [
        "## Setting\n",
        "\n",
        "- 학습 환경에 맞게 조정하기 (특히 **경로 설정**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV_gm5svfMI6"
      },
      "outputs": [],
      "source": [
        "MANUAL_TRAINING = True\n",
        "MANUAL_VALIDATION = True\n",
        "MID_CHECKPOINT_NUM = 2\n",
        "MID_PROCESS_PRINT_NUM = 35\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "learning_rate = 2e-5\n",
        "decay = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxst3tGKfMI7"
      },
      "outputs": [],
      "source": [
        "t5_large_summary_checkpoint = 'lcw99/t5-large-korean-text-summary'\n",
        "t5_base_summary_checkpoint = 'eenzeenee/t5-base-korean-summarization'\n",
        "kobart_summary_checkpoint = 'gogamza/kobart-summarization'\n",
        "kolongformer = \"psyche/kolongformer-4096\"\n",
        "longt5_checkpoint = 'KETI-AIR-Downstream/long-ke-t5-base-summarization'\n",
        "checkpoint = longt5_checkpoint\n",
        "print(f'Using Checkpoint: {checkpoint}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHSgjDWSfMI7"
      },
      "outputs": [],
      "source": [
        "original_dataset_path = './data/dataset-term-summary.json'\n",
        "tokenized_dataset_path = f'./data/{checkpoint.replace(\"/\", \"-\")}-tokenized-dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQVJqEadfMI7"
      },
      "outputs": [],
      "source": [
        "SAVE_STR = datetime.datetime.now().strftime('%y%m%d-%H:%M')\n",
        "model_save_path = f\"./model/{SAVE_STR}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Y11jgZfMI7"
      },
      "source": [
        "## Load Tokenizer & Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXVVhDgMfMI8"
      },
      "outputs": [],
      "source": [
        "if 'bart' in checkpoint.lower():\n",
        "    config = BartConfig.from_pretrained(checkpoint)\n",
        "    #config['vocab'] = 30000\n",
        "elif \"t5\" in checkpoint.lower():\n",
        "    config = T5Config.from_pretrained(checkpoint)\n",
        "elif \"longformer\" in checkpoint.lower():\n",
        "    config = LongformerConfig.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsdQeOO_fMI8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,\n",
        "                                          max_new_tokens=4096,\n",
        "                                          truncation=False,\n",
        "                                          padding='max_length',\n",
        "                                          #vocab=config.vocab_size\n",
        "                                          )\n",
        "#tokenizer = LongformerTokenizer(vocab_file, merges_file, errors='replace', bos_token='<s>', eos_token='</s>', sep_token='</s>', cls_token='<s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>', add_prefix_space=False, **kwargs)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uR1-03QMfMI8"
      },
      "outputs": [],
      "source": [
        "if len(tokenizer) != model.config.vocab_size:\n",
        "    raise RuntimeError(f'Tokenizer vocab size and model vocab size do not match(Tokenizer:{len(tokenizer)} Model: {model.config.vocab_size}). Which would lead to further error in training.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsahbR7qfMI8"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjmBE4GtfMI8"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(tokenized_dataset_path):\n",
        "    dataset = Dataset.from_pandas(pd.read_json(original_dataset_path, encoding='utf-8')[['text', 'summary']])\n",
        "    tokenizer_wrapper = Seq2SeqTokenizeMapWrapper(tokenizer, 'text', 'summary')\n",
        "\n",
        "    tokenized_dataset = (dataset\n",
        "                         .map(tokenizer_wrapper,\n",
        "                              batched=True,\n",
        "                              batch_size=128,\n",
        "                              num_proc=10\n",
        "                              )\n",
        "                         .remove_columns(['text', 'summary'])\n",
        "                         )\n",
        "\n",
        "    tokenized_dataset_dict = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
        "    tokenized_dataset_dict.save_to_disk(tokenized_dataset_path)\n",
        "else:\n",
        "    tokenized_dataset_dict = load_from_disk(tokenized_dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la5Z0jvzfMI9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6Pu0iNBYhvN"
      },
      "outputs": [],
      "source": [
        "print(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBCCNEn72n0H"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, tokenizer, input):\n",
        "    # 생성 전략\n",
        "    generated_ids = model.generate(**input, max_new_tokens=300, top_p=0.92, top_k=0, early_stopping=True)\n",
        "    generated_text = tokenizer.decode(generated_ids.squeeze(0), skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "def generate_input_target(model, tokenizer, input, label):\n",
        "    input_text = tokenizer.decode(input['input_ids'].squeeze(0), skip_special_tokens=True)\n",
        "    generated_text = generate_seq(model, tokenizer, input)\n",
        "    target_text = tokenizer.decode(label.squeeze(0), skip_special_tokens=True)\n",
        "\n",
        "    return {\n",
        "        'input_text': input_text,\n",
        "        'generated_text': generated_text,\n",
        "        'target_text': target_text\n",
        "    }\n",
        "\n",
        "def generate_from_data(model, tokenizer, data):\n",
        "    label = data['labels']\n",
        "    input_data = dict()\n",
        "    input_data['input_ids'] = data['input_ids']\n",
        "    input_data['attention_mask'] = data['attention_mask']\n",
        "\n",
        "    return generate_input_target(model, tokenizer, input_data, label)\n",
        "\n",
        "def eval_bleu_rouge(model, tokenizer, tokenized_testset):\n",
        "    rouge = Rouge()\n",
        "    score_dict = dict()\n",
        "    score_dict['BLEU'] = []\n",
        "    score_dict['ROUGE-Precision'] = []\n",
        "    score_dict['ROUGE-Recall'] = []\n",
        "    score_dict['ROUGE-F1'] = []\n",
        "    eval_tqdm_bar = tqdm(tokenized_testset, leave=False, desc='Evaluating')\n",
        "    for example in eval_tqdm_bar:\n",
        "        data = dict()\n",
        "        for key in example:\n",
        "            data[key] = example[key].unsqueeze(0)\n",
        "        output = generate_from_data(model, tokenizer, data)\n",
        "        try:\n",
        "            bleu_score = sentence_bleu([output['target_text']],\n",
        "                                       output['generated_text'],\n",
        "                                       smoothing_function=SmoothingFunction().method1\n",
        "            )\n",
        "            rouge_score = rouge.get_scores(output['generated_text'],\n",
        "                                           output['target_text']\n",
        "            )\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        score_dict['BLEU'].append(bleu_score)\n",
        "        score_dict['ROUGE-Precision'].append(rouge_score[0]['rouge-2']['p'])\n",
        "        score_dict['ROUGE-Recall'].append(rouge_score[0]['rouge-2']['r'])\n",
        "        score_dict['ROUGE-F1'].append(rouge_score[0]['rouge-2']['f'])\n",
        "\n",
        "    return pd.DataFrame(score_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCWqp_lLveOQ"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "def dict_to_str(d):\n",
        "    return '\\t'.join([f'{k}: {v}' for k, v in d.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_32x5WAveOQ"
      },
      "outputs": [],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=decay,\n",
        "    report_to=\"tensorboard\",\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqofMOt9veOR"
      },
      "outputs": [],
      "source": [
        "## finding the best parameters\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "total_loss = []\n",
        "epoch_loss = []\n",
        "batch_loss = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "trainset = tokenized_dataset_dict['train'].with_format('torch', device=device)\n",
        "testset = tokenized_dataset_dict['test'].with_format('torch', device=device)\n",
        "dataloader = DataLoader(trainset, batch_size=12, shuffle=False) # TODO: Batch size 조절\n",
        "\n",
        "# TODO: Minor Hyperparameter Tuning\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=decay)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=NUM_EPOCHS * len(dataloader))\n",
        "training_stats = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlTAoWk9CX2F"
      },
      "outputs": [],
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    total_steps = len(dataloader)\n",
        "    save_divisor = total_steps // MID_CHECKPOINT_NUM\n",
        "    print_divisor = total_steps // MID_PROCESS_PRINT_NUM\n",
        "    with tqdm(dataloader, leave=False, desc='Batch', position=0, postfix={'Epoch': 1, 'Batch': 1, 'loss': 0, 'loss_mean': 0, 'BLEU': 0, 'ROUGE': 0}) as tqdm_bar:\n",
        "        for i, batch in enumerate(tqdm_bar):\n",
        "            tqdm_bar.set_description(f'Batch: {i + 1}')\n",
        "            X = {\n",
        "                    'input_ids': batch['input_ids'],\n",
        "                    'attention_mask': batch['attention_mask'],\n",
        "                }\n",
        "            y = batch['labels']\n",
        "\n",
        "            outputs = model(**X, labels=y)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            if i % print_divisor == print_divisor - 1:\n",
        "                epoch_loss += batch_loss\n",
        "                batch_loss_series = pd.Series(batch_loss, dtype=np.float64)\n",
        "                metric = eval_bleu_rouge(model, tokenizer, testset)\n",
        "                training_stats.append(\n",
        "                    {\n",
        "                        'Epoch': epoch + 1,\n",
        "                        'Batch': i + 1,\n",
        "                        'loss': loss.item(),\n",
        "                        'loss_mean': batch_loss_series.mean(),\n",
        "                        'BLEU': metric['BLEU'].mean(),\n",
        "                        'ROUGE': metric['ROUGE-F1'].mean()\n",
        "                    }\n",
        "                )\n",
        "                tqdm_bar.set_postfix(training_stats[-1])\n",
        "                batch_loss = []\n",
        "\n",
        "            if i % save_divisor == save_divisor - 1:\n",
        "                trainer.create_model_card(\n",
        "                    language='Korean',\n",
        "                    finetuned_from=checkpoint\n",
        "                )\n",
        "                trainer.save_model(model_save_path + checkpoint + f'-epoch-{epoch + 1}' + f'-batch-{i + 1}')\n",
        "\n",
        "            total_loss += epoch_loss\n",
        "            batch_loss_series = pd.Series(epoch_loss, dtype=np.float64)\n",
        "            epoch_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuuENiy4veOR"
      },
      "outputs": [],
      "source": [
        "metric = eval_bleu_rouge(model, tokenizer, testset)\n",
        "metric.to_csv('./metric.csv')\n",
        "\n",
        "training_stats_df = pd.DataFrame(training_stats)\n",
        "training_stats_df.to_csv('./training_stats.csv')\n",
        "\n",
        "trainer.create_model_card(\n",
        "    language='Korean',\n",
        "    finetuned_from=checkpoint\n",
        ")\n",
        "trainer.save_model(model_save_path + '-final')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GItpvbJjlINj"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xCEXWXWveOR"
      },
      "outputs": [],
      "source": [
        "training_stats_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVLeLjxylOg8"
      },
      "outputs": [],
      "source": [
        "total_loss = pd.Series(total_loss)\n",
        "total_loss.plot.line()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P6A_W2W1u8K"
      },
      "outputs": [],
      "source": [
        "training_stats_df['loss_mean'].plot.line()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTR4NpM-veOS"
      },
      "outputs": [],
      "source": [
        "training_stats_df[['BLEU', 'ROUGE']].plot.line()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}