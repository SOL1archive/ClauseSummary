{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "'Process in Colab' if IN_COLAB else 'Process in Local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install transformers\n",
    "    !pip install datasets\n",
    "    !pip install --upgrade accelerate\n",
    "    !pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
    "    !pip install textrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깃허브에서는 빼야됨\n",
    "%cd drive/MyDrive/projects/ClauseSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import datetime\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='%(asctime)s %(message)s', datefmt='%m-%d %H:%M')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_from_disk, load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, LongformerTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import pfrl\n",
    "from textrl import TextRLEnv, TextRLActor, train_agent_with_evaluation\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_newline_before_number(text:str) -> str: #숫자. 형태로 되어있는것에 개행문자를 추가.\n",
    "    text = re.sub(r'(\\d+)\\.',r'\\n\\1.', str(text))\n",
    "    return text\n",
    "\n",
    "def change_it_to_a_comma(text:str): # (1) (2) 형태를 ,으로\n",
    "    items = re.split(r'\\(\\d+\\)', text)\n",
    "    if len(items) > 1:\n",
    "        items[1] = items[0]+items[1]\n",
    "        del items[0]\n",
    "    return ','.join(items)\n",
    "\n",
    "def remove_whitespace_after_str(text:str):\n",
    "    text = re.sub(r\"\\b갑\\s\", r'갑', text)\n",
    "    text = re.sub(r\"\\b을\\s\", r'을', text)\n",
    "    text = re.sub(r\"\\b병\\s\", r'병', text)\n",
    "    text = re.sub(r\"\\b정\\s\", r'정', text)\n",
    "    return text\n",
    "\n",
    "def change_number_point(text:str): # 1. 2. 등을 제 1조 2 항 등으로 바꿔줌\n",
    "    items = re.split(r'\\d+\\.', text)\n",
    "    if len(items) > 1:\n",
    "        items[1] = items[0]+items[1]\n",
    "        del items[0]\n",
    "    return ''.join(items)\n",
    "\n",
    "def summary_preprocessing_func(text: str):\n",
    "    text = add_newline_before_number(text)\n",
    "    text = change_it_to_a_comma(text)\n",
    "    text = remove_whitespace_after_str(text)\n",
    "    text = change_number_point(text)\n",
    "    return text\n",
    "\n",
    "def text_preprocessing_func(text):\n",
    "    return re.sub(r'\\n[\\n ]+', '\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(row: Dict[str, str]):\n",
    "    text = row['text']\n",
    "    summary = row['summary']\n",
    "    text = text_preprocessing_func(text)\n",
    "    summary = summary_preprocessing_func(summary)\n",
    "\n",
    "    return {'text': text, \n",
    "            'summary': summary\n",
    "            }\n",
    "\n",
    "def df_preprocessing(df: pd.DataFrame):\n",
    "    text_df = df[['text', 'summary']]\n",
    "    text_df = text_df.apply(preprocessing, axis=1, result_type='expand')\n",
    "\n",
    "    df[['text', 'summary']] = text_df[['text', 'summary']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizeMapWrapper:\n",
    "    def __init__(self, tokenizer, feature, option=None):\n",
    "        if option is None:\n",
    "            option = {\n",
    "                'max_length': 4096,\n",
    "                'truncation': True,\n",
    "                'padding': 'max_length',\n",
    "            }\n",
    "        \n",
    "        self.feature = feature\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return self.tokenizer(row[self.feature], **self.option)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(tokenizer={self.tokenizer})'\n",
    "\n",
    "class RewardTokenizeMapWrapper(TokenizeMapWrapper):\n",
    "    def __init__(self, tokenizer, feature, max_token=4096, option=None):\n",
    "        if option is None:\n",
    "            option = {\n",
    "                'max_length': max_token,\n",
    "                'truncation': True,\n",
    "            }\n",
    "\n",
    "        self.max_token = option['max_new_tokens']\n",
    "        self.option = option\n",
    "        self.feature = feature\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, row):\n",
    "        total_text = row[self.feature]\n",
    "        if len(re.findall('\\nSummary: \\n', total_text)) == 1:\n",
    "            text, summary = total_text.split('Summary: \\n')\n",
    "            summary = '\\nSummary: \\n' + summary\n",
    "        else:\n",
    "            print('warning: more than two summary exists')\n",
    "            text_split = total_text.split('Summary: \\n')\n",
    "            text = text_split[0]\n",
    "            summary = '\\nSummary: \\n'.join(text_split[1:])\n",
    "        \n",
    "        tokenized_text = self.tokenizer(text, **self.option)\n",
    "        tokenized_summary = self.tokenizer(summary, **self.option)\n",
    "        tokenized_total_text = dict()\n",
    "        if len(tokenized_text['input_ids']) + len(tokenized_summary['input_ids']) <= self.max_token:\n",
    "            for key in tokenized_text:\n",
    "                tokenized_total_text[key] = tokenized_text[key] + tokenized_summary[key]\n",
    "                if len(tokenized_total_text[key]) < self.max_token:\n",
    "                    tokenized_total_text[key] = (tokenized_total_text[key] \n",
    "                                                 + [1] * (self.max_token - len(tokenized_total_text[key]))\n",
    "                    )\n",
    "        else:\n",
    "            for key in tokenized_text:\n",
    "                tokenized_total_text[key] = (tokenized_text[key][:- len(tokenized_summary['input_ids'])] \n",
    "                                             + tokenized_summary[key]\n",
    "                )\n",
    "\n",
    "        return tokenized_total_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelForRewardGeneration(nn.Module):\n",
    "    def __init__(self, encoder_path, hidden_size=256):\n",
    "        super(ModelForRewardGeneration, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_path)\n",
    "        self.hidden_size = hidden_size\n",
    "        # TODO: head 설계\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(768, hidden_size, bias=False),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout1d(0.1),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        x = self.encoder(input_ids, attention_mask).pooler_output\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "def reference_reward_loss(reward, pred):\n",
    "    return - torch.log10(1 + torch.exp(-reward * pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_TRAINING = True\n",
    "MANUAL_VALIDATION = True\n",
    "MID_CHECKPOINT_NUM = 2\n",
    "MID_PROCESS_PRINT_NUM = 35\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "MAX_TOKEN = 4096\n",
    "learning_rate = 2e-5\n",
    "decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model_checkpoint = 'psyche/kolongformer-4096'\n",
    "reward_model_path = './model/230705-10 59'\n",
    "summary_model_checkpoint = 'KETI-AIR-Downstream/long-ke-t5-base-summarization'\n",
    "\n",
    "print(f'reward_model_checkpoint: {reward_model_checkpoint}\\nsummary_model_checkpoint: {summary_model_checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_path = './data/dataset-term.json'\n",
    "tokenized_dataset_path = f'./data/{summary_model_checkpoint.replace(\"/\", \"-\")}-tokenized-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_STR = datetime.datetime.now().strftime('%y%m%d-%H:%M')\n",
    "model_save_path = f\"./model/{SAVE_STR}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer & Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tokenizer = AutoTokenizer.from_pretrained(summary_model_checkpoint)\n",
    "reward_tokenizer = LongformerTokenizer.from_pretrained(reward_model_checkpoint)\n",
    "\n",
    "summary_model = AutoModelForSeq2SeqLM.from_pretrained(summary_model_checkpoint)\n",
    "reward_model = ModelForRewardGeneration(reward_model_checkpoint)\n",
    "reward_model.encoder = AutoModel.from_pretrained(reward_model_path + '-encoder-final')\n",
    "reward_model.head.load_state_dict(torch.load(reward_model_path + '-head-final.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(original_dataset_path, encoding='utf-8')\n",
    "\n",
    "if not os.path.exists(tokenized_dataset_path):\n",
    "    dataset = Dataset.from_pandas(df[['text']])\n",
    "    \n",
    "    tokenizer_wrapper = TokenizeMapWrapper(summary_tokenizer, 'text')\n",
    "\n",
    "    tokenized_dataset = (dataset\n",
    "                         .map(tokenizer_wrapper,\n",
    "                              batched=True,\n",
    "                              batch_size=128,\n",
    "                              num_proc=10\n",
    "                              )\n",
    "                         .remove_columns(['text'])\n",
    "                         )\n",
    "\n",
    "    tokenized_dataset_dict = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "    tokenized_dataset_dict.save_to_disk(tokenized_dataset_path)\n",
    "else:\n",
    "    tokenized_dataset_dict = load_from_disk(tokenized_dataset_path)\n",
    "\n",
    "df['input'] = df['text']\n",
    "df = df.drop(columns=['text'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding the best parameters\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "total_loss = []\n",
    "epoch_loss = []\n",
    "batch_loss = []\n",
    "\n",
    "summary_model.train()\n",
    "reward_model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trainset = tokenized_dataset_dict['train'].with_format('torch', device=device)\n",
    "testset = tokenized_dataset_dict['test'].with_format('torch', device=device)\n",
    "dataloader = DataLoader(trainset, batch_size=12, shuffle=False) # TODO: Batch size 조절\n",
    "\n",
    "# TODO: Minor Hyperparameter Tuning\n",
    "criterion = MSELoss()\n",
    "optimizer = AdamW(summary_model.parameters(), lr=learning_rate, weight_decay=decay)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=NUM_EPOCHS * len(dataloader))\n",
    "training_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "option = {\n",
    "    'max_new_tokens': MAX_TOKEN,\n",
    "    'truncation': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish):\n",
    "        reward = [0]\n",
    "        if finish:\n",
    "            tokenized_text = reward_tokenizer(input_item['text'], **option)\n",
    "            tokenized_summary = reward_tokenizer(predicted_list[0], **option)\n",
    "\n",
    "            tokenized_total_text = dict()\n",
    "            for key in tokenized_text:\n",
    "                if len(tokenized_text['input_ids']) + len(tokenized_summary['input_ids']) < self.max_token:\n",
    "                    tokenized_total_text[key] = tokenized_text[key] + tokenized_summary[key]\n",
    "                else:\n",
    "                    tokenized_total_text[key] = (tokenized_text[key][:- len(tokenized_summary['input_ids'])]\n",
    "                                                 + tokenized_summary[key]\n",
    "                    )\n",
    "                tokenized_total_text[key] = (tokenized_total_text[key] \n",
    "                                             + ([1] * (self.max_token - len(tokenized_total_text[key])))\n",
    "                )\n",
    "            reward = [float(reward_model(**tokenized_total_text).squeeze()) * 10]\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SummaryRLEnv(summary_model, summary_tokenizer, observation_input=df.to_dict(), compare_sample=len(dataset))\n",
    "actor = TextRLActor(env, summary_model, summary_tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent_with_evaluation(\n",
    "    agent=agent,\n",
    "    env=env,\n",
    "    steps=300,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=1,\n",
    "    train_max_episode_len=300,\n",
    "    eval_interval=10,\n",
    "    outdir=model_save_path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
